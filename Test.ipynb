{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8beedc87-4cfa-4d0d-9ade-a2ce7ce5722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import tensorflow as tf\n",
    "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "218f437e-8667-47e7-a8ba-e316e35446c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08052f50-9534-4196-98a5-a71e8ccfcfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(input):\n",
    "    input_ids = tokenizer.encode(input, return_tensors='tf')\n",
    "    beam_output = model.generate(input_ids, max_length=100, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)\n",
    "    output = tokenizer.decode(beam_output[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    return \".\".join(output.split(\".\")[:-1]) + \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "887969bd-96ea-41ae-ace5-3f554286c040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7865\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo = gr.Interface(fn=generate_text, inputs=\"textbox\", outputs=\"textbox\", title=\"TEXT_GENERATION_GPT-2\",\n",
    "                    description=\"OpenAI's GPT-2 is an unsupervised language model that can produce coherent text. \\\n",
    "                    Go ahead and ask a question and see what it comes up with! \\nTime taken : 20s\")\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
